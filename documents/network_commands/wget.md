Команда `wget` (World Wide Web Get) — це проста утиліта для завантаження файлів з інтернету. Вона може працювати у фоновому режимі, відновлювати перервані завантаження та рекурсивно завантажувати цілі сайти.

#### **Базовий синтаксис**

```bash
wget [опції] [URL]
```

--- 

### **Основні опції**

| Опція | Пояснення |
| :--- | :--- |
| **`-O /шлях/до/файлу`** | Зберегти файл під іншим іменем або в іншій директорії. |
| **`-c`**, **`--continue`** | Продовжити завантаження файлу, якщо воно було перервано. |
| **`-b`**, **`--background`** | Запустити завантаження у фоновому режимі. |
| **`-r`**, **`--recursive`** | Рекурсивно завантажувати сайт (слідувати за посиланнями). |
| **`-l РІВЕНЬ`**, **`--level=РІВЕНЬ`** | Вказати глибину рекурсії (за замовчуванням 5). |
| **`-p`**, **`--page-requisites`** | Завантажити всі необхідні для відображення сторінки файли (зображення, CSS тощо). |
| **`-k`**, **`--convert-links`** | Після завантаження перетворити посилання в документах на локальні. |
| **`--no-check-certificate`** | Не перевіряти SSL-сертифікат сервера (використовуйте з обережністю). |

--- 

### **Приклади використання**

1.  **Просте завантаження файлу:**
    Файл буде збережено в поточній директорії під оригінальним іменем.
    ```bash
    wget https://wordpress.org/latest.zip
    ```

2.  **Завантаження файлу під іншим іменем:**
    ```bash
    wget -O wp.zip https://wordpress.org/latest.zip
    ```

3.  **Відновлення перерваного завантаження:**
    Якщо завантаження великого файлу обірвалося, ця команда продовжить його з місця розриву.
    ```bash
    wget -c https://releases.ubuntu.com/22.04/ubuntu-22.04.3-desktop-amd64.iso
    ```

4.  **Завантаження у фоновому режимі:**
    ```bash
    wget -b https://example.com/large-file.zip
    ```
    *Прогрес завантаження буде записуватися у файл `wget-log`.*

5.  **Створення повної офлайн-копії сайту:**
    Ця комбінація опцій дозволяє завантажити сайт для перегляду в офлайні.
    ```bash
    wget --recursive --no-clobber --page-requisites --html-extension --convert-links --domains example.com --no-parent https://example.com
    ```
    *   `--recursive`: рекурсивне завантаження.
    *   `--no-clobber`: не перезаписувати існуючі файли.
    *   `--page-requisites`: завантажувати всі елементи сторінки.
    *   `--html-extension`: конвертувати сторінки в `.html`.
    *   `--convert-links`: зробити посилання локальними.
    *   `--domains example.com`: не виходити за межі вказаного домену.
    *   `--no-parent`: не підніматися вище початкової директорії.

6.  **Завантаження файлів зі списку:**
    Якщо у вас є файл `urls.txt` зі списком URL, кожен на новому рядку.
    ```bash
    wget -i urls.txt
    ```

`wget` — це потужний інструмент, особливо для автоматизації завантажень у скриптах.
